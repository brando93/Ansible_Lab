# FastAPI AI Application

## ğŸš€ CaracterÃ­sticas

- **Modo Mock (RÃ¡pido)**: Respuestas instantÃ¡neas para desarrollo
- **Modo Full (IA Real)**: Modelo distilgpt2 de Hugging Face
- **CachÃ© Persistente**: Los modelos se guardan en volÃºmenes Docker
- **Health Check**: Endpoint `/health` para monitoreo

## ğŸ¯ Modos de OperaciÃ³n

### Modo Mock (Por defecto en DEV)
- âš¡ Inicio instantÃ¡neo (~5 segundos)
- ğŸ’¾ Imagen ligera (~500MB)
- ğŸ”„ Respuestas predefinidas rÃ¡pidas
- âœ… Ideal para desarrollo y testing

### Modo Full (Por defecto en PROD)
- ğŸ¤– Modelo real de IA (distilgpt2)
- ğŸ“¦ Primera descarga: ~250MB
- â±ï¸ Primer inicio: 1-2 minutos
- ğŸ”„ Siguientes inicios: ~30 segundos (usa cachÃ©)
- âœ… Ideal para producciÃ³n

## ğŸ“¡ Endpoints

### Health Check
```bash
curl http://localhost:8001/health
```

Respuesta:
```json
{
  "status": "ok",
  "environment": "dev"
}
```

### PredicciÃ³n (Mock Mode)
```bash
curl -X POST http://localhost:8001/predict \
  -H "Content-Type: application/json" \
  -d '{"text": "hello"}'
```

Respuesta:
```json
{
  "result": "hello Hello! I'm a FastAPI mock model. How can I help you today?"
}
```

### PredicciÃ³n (Full Mode)
```bash
curl -X POST http://localhost:8002/predict \
  -H "Content-Type: application/json" \
  -d '{"text": "The future of AI is"}'
```

Respuesta (generada por IA):
```json
{
  "result": "The future of AI is bright and full of possibilities..."
}
```

## ğŸ”§ ConfiguraciÃ³n

### Cambiar modo en DEV a Full
Edita `ansible-lab/ansible/group_vars/dev.yml`:
```yaml
model_mode: full  # Cambiar de 'mock' a 'full'
```

### Cambiar modo en PROD a Mock
Edita `ansible-lab/ansible/group_vars/prod.yml`:
```yaml
model_mode: mock  # Cambiar de 'full' a 'mock'
```

## ğŸ’¾ Persistencia

Los modelos de IA se guardan en volÃºmenes Docker:
- `fastapi-cache-dev`: CachÃ© para entorno dev
- `fastapi-cache-prod`: CachÃ© para entorno prod

**Ventaja**: Cuando bajas y subes el ambiente, el modelo ya estÃ¡ descargado y el inicio es rÃ¡pido.

## ğŸ³ Puertos

- **DEV**: `http://localhost:8001`
- **PROD**: `http://localhost:8002`

## ğŸ“Š Recursos

### Modo Mock
- RAM: ~200MB
- Disco: ~500MB
- CPU: Bajo

### Modo Full
- RAM: ~1-2GB
- Disco: ~2GB (primera vez), ~500MB (con cachÃ©)
- CPU: Medio-Alto durante inferencia

## ğŸ§ª Testing RÃ¡pido

```bash
# Health check
curl http://localhost:8001/health

# PredicciÃ³n simple
curl -X POST http://localhost:8001/predict \
  -H "Content-Type: application/json" \
  -d '{"text": "hello"}'

# PredicciÃ³n con pregunta
curl -X POST http://localhost:8001/predict \
  -H "Content-Type: application/json" \
  -d '{"text": "how are you"}'
```

## ğŸ”„ Workflow Recomendado

1. **Desarrollo**: Usa modo `mock` en DEV para iteraciÃ³n rÃ¡pida
2. **Testing**: Cambia a modo `full` en DEV para probar el modelo real
3. **ProducciÃ³n**: Usa modo `full` en PROD con cachÃ© persistente
4. **CI/CD**: Jenkins despliega automÃ¡ticamente segÃºn configuraciÃ³n

## ğŸ“ Variables de Entorno

- `ENV`: Entorno (dev/prod)
- `MODEL_MODE`: Modo del modelo (mock/full)
- `HF_HOME`: Directorio de cachÃ© de Hugging Face
- `TRANSFORMERS_CACHE`: CachÃ© de transformers

## ğŸ“ Ejemplos de Prompts (Modo Full)

```bash
# GeneraciÃ³n de texto
curl -X POST http://localhost:8002/predict \
  -H "Content-Type: application/json" \
  -d '{"text": "Once upon a time"}'

# ContinuaciÃ³n de historia
curl -X POST http://localhost:8002/predict \
  -H "Content-Type: application/json" \
  -d '{"text": "In a world where AI"}'

# Pregunta abierta
curl -X POST http://localhost:8002/predict \
  -H "Content-Type: application/json" \
  -d '{"text": "What is the meaning of"}'